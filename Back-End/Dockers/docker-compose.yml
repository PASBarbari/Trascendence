version: '3.8'
# TODO add the celery wrokers and the celery beat
services:
  usertask_db:
    build:
      context: ./usertask_db
      dockerfile: Dockerfile
    container_name: container_usertask_db
    ports:
      - "5434:5432"
    networks:
      - back-end
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U pasquale -d usertask_db"]
      interval: 30s
      timeout: 10s
      retries: 5

  usertask_service:
    build:
      context: ./usertask_service
      dockerfile: Dockerfile
    container_name: container_usertask_service
    ports:
      - "8002:8000"

  login_db:
    build:
      context: ./login_db
      dockerfile: Dockerfile
    container_name: container_login_db
    ports:
      - "5435:5432"
    networks:
      - back-end
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U pasquale -d login_db"]
      interval: 30s
      timeout: 10s
      retries: 5
    env_file:
      - ./login_service/.env

  login_service:
    build:
      context: ./login_service
      dockerfile: Dockerfile
    container_name: container_login_service
    ports:
      - "8000:8000"
    networks:
      - back-end
    env_file:
      - ./login_service/.env
    depends_on:
      login_db:
        condition: service_healthy

  chat_db:
    build:
      context: ./chat_db
      dockerfile: Dockerfile
    container_name: container_chat_db
    ports:
      - "5436:5432"
    networks:
      - back-end
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U pasquale -d chat_db"]
      interval: 30s
      timeout: 10s
      retries: 5
  
  chat_service:
    build:
      context: ./chat_service
      dockerfile: Dockerfile
    container_name: container_chat_service
    ports:
      - "8001:8000"

  notification_db:
    build:
      context: ./notification_db
      dockerfile: Dockerfile
    container_name: container_notification_db
    ports:
      - "5437:5432"
    networks:
      - back-end
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U pasquale -d notification_db"]
      interval: 30s
      timeout: 10s
      retries: 5

  notification_service:
    build:
      context: ./notification_service
      dockerfile: Dockerfile
    container_name: container_notification_service
    ports:
      - "8003:8000"

  redis_chat:
    image: "redis:latest"
    ports:
      - "6700:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - back-end

  redis_notification:
    image: "redis:latest"
    ports:
      - "6701:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - back-end

  celery_worker_notificaton:
    build:
      context: ./celery_notification
      dockerfile: Dockerfile
    container_name: celery_worker_notification
    networks:
      - back-end
    depends_on:
      - notification_db
      - redis_notification

  prometheus:
    build:
      context: ./prometheus
      dockerfile: Dockerfile
    container_name: prometheus
    ports:
      - "9091:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    networks:
      - back-end

  loki:
    build:
      context: ./loki
      dockerfile: Dockerfile
    container_name: loki
    ports:
      - "3101:3100"
    volumes:
      - ./loki/loki-config.yaml:/etc/loki/local-config.yaml
      - loki-data:/var/lib/loki
    networks:
      - back-end

  grafana:
    build:
      context: ./grafana
      dockerfile: Dockerfile
    container_name: grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin  # TODO: Change this password
    volumes:
      - ./grafana/provisioning/datasources:/etc/grafana/provisioning/datasources
      - grafana-data:/var/lib/grafana
    depends_on:
      - prometheus
      - loki
    networks:
      - back-end

  promtail:
    image: grafana/promtail:latest
    container_name: promtail
    volumes:
      - /var/log:/var/log
      - ./promtail/promtail-config.yaml:/etc/promtail/config.yaml
      - ./promtail/positions.yaml:/tmp/positions.yaml  # Persist positions file
    networks:
      - back-end
    depends_on:
      - loki
  postgres_exporter:
    image: prometheuscommunity/postgres-exporter
    container_name: postgres_exporter
    environment:
      DATA_SOURCE_NAME: "postgresql://pasquale:123@container_usertask_db:5432/usertask_db?sslmode=disable,postgresql://pasquale:123@container_login_db:5432/login_db?sslmode=disable,postgresql://pasquale:123@container_chat_db:5432/chat_db?sslmode=disable"
    ports:
      - "9187:9187"
    networks:
      - back-end
    depends_on:
      - usertask_db
      - login_db
      - chat_db

  redis_exporter:
    image: bitnami/redis-exporter:latest
    container_name: redis_exporter
    environment:
      - REDIS_ADDR=redis:6379
    ports:
      - "9121:9121"
    networks:
      - back-end
volumes:
  prometheus_data: {}
  loki-data: {}
  grafana-data: {}

networks:
  usertask_network:
    driver: bridge
  chat_network:
    driver: bridge
  login_network:
    driver: bridge
  internal_notification_network:
    driver: bridge
  exporters_network:
    driver: bridge
  auth_network:
    driver: bridge
  logging_network:
    driver: bridge
  notification_network:
    driver: bridge
  back-end:
    driver: bridge
